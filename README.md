# ğŸ§  Data Warehouse & Analytics Project

Welcome to the **Data Warehouse & Analytics Project** repository! ğŸ‘¨ğŸ»â€ğŸ’»âœ¨  
This portfolio project demonstrates a complete **end-to-end pipeline** â€“ from structured **data integration** to insightful **analytics** â€“ following best practices in **modern data engineering**.

---

## ğŸ§‘ğŸ»â€ğŸ”¬ Project Overview

### ğŸ—ï¸ Part 1: Building the Data Warehouse (Data Engineering)

**ğŸ¯ Objective:**  
Design and implement a **data warehouse** using SQL Server to consolidate ERP and CRM data, enabling clean, integrated, and analytics-ready datasets.

**ğŸ“‹ Key Features:**

- **Data Sources**: Load raw data from two systems â€“ ERP and CRM (CSV format).
- **Data Quality**: Perform cleansing, normalization, and deduplication.
- **Integration Logic**: Resolve key conflicts and enrich customer & product profiles.
- **Architecture**: Apply a classic **ETL pipeline**: Bronze â†’ Silver â†’ Gold.
- **Scope**: Work with the latest snapshot (no historization).
- **Documentation**: Deliver technical and business-readable documentation (Markdown & SQL comments).

---

### ğŸ“Š Part 2: BI & Analytics (Data Analytics)

**ğŸ¯ Objective:**  
Generate business-relevant insights through SQL-based analysis to support **data-driven decisions**.

**ğŸ“Œ Analytical Focus Areas:**

- ğŸ“ˆ **Customer behavior** â€“ demographics, engagement
- ğŸ›ï¸ **Product performance** â€“ categories, cost, lifecycle
- ğŸ’¸ **Sales metrics** â€“ revenue, timing, quantity

The resulting views (dim & fact tables) are designed to be consumed by BI tools such as **Power BI** or **Tableau**.

---

## ğŸ› ï¸ Tools & Technologies Used

| Tool             | Purpose                                          |
|------------------|--------------------------------------------------|
| **PostgreSQL**   | Database engine for DWH implementation           |
| **DataGrip**     | SQL IDE for writing and executing queries        |
| **Canva**        | Visualization tool for diagrams and models       |
| **Notion**       | Project documentation and research notes         |
| **Markdown**     | Documentation in GitHub and Data Catalogs        |
| **Git / GitHub** | Version control and collaboration                |


---

## ğŸ§© Architecture Overview

```plaintext
[ Raw CSVs ]
     â†“
[ Bronze Layer ] â€” raw staging
     â†“
[ Silver Layer ] â€” cleaned, joined, enriched
     â†“
[ Gold Layer ] â€” analytics-ready dimensional model
```

---

## ğŸ“ Repository Structure

```
Data Warehouse Project/
â”‚
â”œâ”€â”€ ğŸ“‚ Datasets/                          # Raw source data from ERP and CRM systems
â”‚   â”œâ”€â”€ ğŸ“‚ Source_CRM/                   # CRM data source (customer & sales data)
â”‚   â”‚   â”œâ”€â”€ cust_info.csv                # Customer information (CRM)
â”‚   â”‚   â”œâ”€â”€ prd_info.csv                 # Product information (CRM)
â”‚   â”‚   â””â”€â”€ sales_details.csv            # Sales transactions (CRM)
â”‚   â””â”€â”€ ğŸ“‚ Source_ERP/                   # ERP data source (enrichment and lookup)
â”‚       â”œâ”€â”€ CUST_AZ12.csv                # Customer attributes from ERP
â”‚       â”œâ”€â”€ LOC_A101.csv                 # Location details from ERP
â”‚       â””â”€â”€ PX_CAT_G1V2.csv              # Product category mappings
â”‚
â”œâ”€â”€ ğŸ“‚ Documentations/                   # Project documentation and diagrams
â”‚   â”œâ”€â”€ Data_Architecture.png            # Diagram of the data architecture
â”‚   â”œâ”€â”€ Data_Catalog/                    # Markdown-based data dictionary
â”‚   â”œâ”€â”€ Data_Flow.png                    # Visual data flow across layers
â”‚   â”œâ”€â”€ Data_Schema.png                  # Entity-Relationship diagram of the DWH
â”‚   â”œâ”€â”€ Integration_Model.png            # Data integration overview (CRM + ERP)
â”‚   â””â”€â”€ Naming_Conventions/             # Standards for naming tables, columns, etc.
â”‚
â”œâ”€â”€ ğŸ“œ README.md                         # Project overview and instructions
â”‚
â”œâ”€â”€ ğŸ“‚ Scripts/                          # SQL scripts for all data engineering layers
â”‚   â”œâ”€â”€ Init_Database.sql               # Initializes database and schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Layers_Creation/             # DDL and ETL logic per DWH layer
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ Bronze/                  # Bronze layer scripts (raw ingestion)
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_Load_Bronze_Layer.sql
â”‚   â”‚   â”‚   â””â”€â”€ DDL_Bronze.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ Silver/                  # Silver layer scripts (cleansing + modeling)
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_Load_Silver_Layer.sql
â”‚   â”‚   â”‚   â””â”€â”€ DDL_Silver.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“‚ Gold/                    # Gold layer scripts (business views)
â”‚   â”‚       â””â”€â”€ DDL_Gold.sql
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ Quality_Checks/              # Data validation scripts per layer
â”‚       â”œâ”€â”€ Quality_Checks_Gold.sql
â”‚       â””â”€â”€ Quality_Checks_Silver.sql
```

---

## âœ… Project Status

ğŸ‰ **Initial version complete!**  
This repository contains a stable and functional ETL + Analytics pipeline.  
Further additions (e.g., dashboards, performance tuning, advanced queries) are welcome and may follow.

---

## ğŸ“š Learnings & Reflections

This project marks my very first experience with **SQL** and **Data Engineering**. While I identify more as a Data Analyst, I deliberately chose to build this project to better understand the **underlying data infrastructure** that powers analytics. 
I approached the architecture methodically, yet allowed room for exploration, experimentation, and iteration. This reflects how I generally work: structured, but open to trial and error.

I selected **PostgreSQL** as my database platform because of its wide adoption in the industry and its readable, intuitive syntax. I worked with **DataGrip** as my IDE because of its modern UI/UX, which I found helpful as a beginner, especially for navigating large schemas and running exploratory queries.

I also made a conscious effort to document the project as if it were used in a real-world setting: with clear naming conventions, well-commented SQL scripts, a detailed data catalog, and diagrammatic visualizations. I used **Canva** to design diagrams, but in future projects I would consider tools like **Figma** for even more flexible and collaborative design work regarding diagrams.

I've also learned how to use **Git** for version control, which I had not used before in a technical setting. I really like it so far. 

This project definitely helped me become more confident in handling **data architecture and pipelines**, and maybe I'll do a follow up with a **Data Analysis project** using the Gold Layer as a foundation. We'll see! ğŸ˜Š


